{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] load data OK: ../data/felix-e500-v30000.pk\n",
      "[2] load model OK!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from multiprocessing import Pool, Manager\n",
    "from os.path import basename, join, dirname, abspath\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append(abspath('../src'))\n",
    "import model.util as util\n",
    "from model.rnn import RNNEncoder\n",
    "from model.bow import BOWEncoder\n",
    "\n",
    "\n",
    "# load checkpoint\n",
    "checkpoint = torch.load('../checkpoint/felix-e500-v30000_h512_p20_l2_d0.0-0.0_b16_gru_Adam_lr0.0001', map_location=lambda storage, loc: storage)\n",
    "\n",
    "# load data\n",
    "model_args = checkpoint['args']\n",
    "with open(model_args.data, 'rb') as rf:\n",
    "    data = pickle.load(rf)\n",
    "dic_embed = data['dic_embed']\n",
    "def_embed = data['def_embed']\n",
    "dic_word2ix = data['dic_word2ix']\n",
    "def_word2ix = data['def_word2ix']\n",
    "dic_ix2word = {v: k for k, v in dic_word2ix.items()}\n",
    "rvd_candidates = set(data['rvd_candidates'])\n",
    "print('[1] load data OK:', model_args.data)\n",
    "\n",
    "# load model\n",
    "model_args.gpu = -1\n",
    "encoder = RNNEncoder(def_word2ix, model_args)\n",
    "encoder.load_state_dict(checkpoint['state_dict'])\n",
    "print('[2] load model OK!')\n",
    "\n",
    "dic_embed = util.normalize_matrix_by_row(dic_embed.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rank_sen(sen):\n",
    "    out_embs = encoder.estimate_from_strsens([sen], normalize=True)\n",
    "    simi_matrix = out_embs.dot(dic_embed.transpose()).reshape(-1)\n",
    "    rank = sorted(range(len(dic_word2ix)), key=lambda i: simi_matrix[i], reverse=True)\n",
    "    return [dic_ix2word[i] for i in rank[:20]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 500)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.estimate_from_strsens(['a fruit', 'hello', 'fwea fwea']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "e = RNNEncoder({}, model_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "While copying the parameter named embed.weight, whose dimensions in the model are torch.Size([]) and whose dimensions in the checkpoint are torch.Size([30003, 500]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/home/ll2/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    481\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m                     \u001b[0mown_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: inconsistent tensor size, expected tensor [] and src [30003 x 500] to have the same number of elements, but got 0 and 15001500 elements respectively at /opt/conda/conda-bld/pytorch_1512387374934/work/torch/lib/TH/generic/THTensorCopy.c:86",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-4a4acc43a311>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/ll2/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    485\u001b[0m                                        \u001b[0;34m'whose dimensions in the model are {} and '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m                                        \u001b[0;34m'whose dimensions in the checkpoint are {}.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m                                        .format(name, own_state[name].size(), param.size()))\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m                 raise KeyError('unexpected key \"{}\" in state_dict'\n",
      "\u001b[0;31mRuntimeError\u001b[0m: While copying the parameter named embed.weight, whose dimensions in the model are torch.Size([]) and whose dimensions in the checkpoint are torch.Size([30003, 500])."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
